{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZLyZ9_Cdrle"
   },
   "source": [
    "<h2 style='color:blue' align='center'>Transfer learning in image classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZxuG4z6drlg"
   },
   "source": [
    "**In this lab, we will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that on flowers dataset. Using pre-trained model saves lot of time and computational budget for the new classification problem at hand**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Hub is a repository of pre-trained TensorFlow models.\n",
    "\n",
    "This tutorial demonstrates how to:\n",
    "* Use models from TensorFlow Hub with tf.keras.\n",
    "* Use an image classification model from TensorFlow Hub.\n",
    "* Do simple transfer learning to fine-tune a model for your own image classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnSOIslVdrlj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import PIL as PIL\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tf_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2wQzUgedrlk"
   },
   "source": [
    "# An ImageNet classifier\n",
    "Start by using a classifier model pre-trained on the ImageNet benchmark data. Ntâ€”no initial trainiis ng requirelow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the classifier\n",
    "\n",
    "Select a **MobileNetV2 pre-trained model** from **TensorFlow Hub** and wrap it as a Keras layer with `hub.KerasLayer`. Any compatible image classifier model from TensorFlow Hub will work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "#inception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n",
    "\n",
    "#classifier_model = mobilenet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IMAGE_SHAPE`\n",
    ":\n",
    "\n",
    " This iy a tuple containing the height and width of the images in your dataset. For example, if your images are 224 pixels tall and 224 pixels wide, IMAGE_SHAPE would be (224, 224)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`+(3,)`: \n",
    "\n",
    "This part adds a third dimension to the IMAGE_SHAPE tuple. This dimension is typically used to represent the number of color channels in the images. For color images, there are 3 channels (red, green, and blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lAOzRRTdrlk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# Define your image shape (height, width)\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "# Load the pre-trained MobileNet V2 model from TensorFlow Hub\n",
    "mobilenet_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\",\n",
    "    input_shape=IMAGE_SHAPE+(3,),  # Specify input shape with color channels\n",
    "    trainable=False  # Freeze the pre-trained weights\n",
    ")\n",
    "\n",
    "# Create a Sequential model\n",
    "classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: mobilenet_model.call(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it on one image\n",
    "\n",
    "Download one image and try the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "6oYv9NYAdrlk",
    "outputId": "05c6cdbe-cf45-49dd-8277-569d35d9ce03",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gold_fish = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/gold_fish.jpg')\n",
    "\n",
    "gold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\n",
    "gold_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBlwC3mxdrll",
    "outputId": "37e43362-f937-4115-c916-782c400b019f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish)/255.0\n",
    "gold_fish.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a batch dimension (with np.newaxis) and pass the image to the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.newaxis`\n",
    ":\n",
    "\n",
    " This is a special value in NumPy that represents a new axis. When used in indexing, it inserts a new dimension into the array at the specified positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`...`: \n",
    "\n",
    "This is called an ellipsis and represents all existing dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT5JDFDMdrll",
    "outputId": "d521144c-c108-42cf-bf5b-fcf7eefdd199"
   },
   "outputs": [],
   "source": [
    "gold_fish[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6Ffphcvdrlm",
    "outputId": "de1aac95-0e89-415d-83ac-4e8fd105eb94"
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(gold_fish[np.newaxis, ...])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a 1001-element vector of logits, rating the probability of each class for the image.\n",
    "\n",
    "The top class ID can be found with tf.math.argmx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34OE33hUdrlm",
    "outputId": "31d76b93-47f9-40fe-d6f3-599ed0984f94"
   },
   "outputs": [],
   "source": [
    "predicted_label_index = np.argmax(result)\n",
    "predicted_label_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the predictions\n",
    "\n",
    "Take the predicte labelsindexD (such as23) and fetch the ImageNet dataset labels to decode the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nT4aTjYidrlm",
    "outputId": "2e77554d-1693-4b3a-faed-bd3a575837e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "image_labels = [] # a list\n",
    "\n",
    "# load image lables from a text file\n",
    "# This code assumes that the file \"ImageNetLabels.txt\" contains one label per line. \n",
    "with open(file_path, \"r\") as f: # with is used to close the file automatically\n",
    "    image_labels = f.read().splitlines()\n",
    "\n",
    "image_labels[:5] # print the first five labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ovVCX61Mdrln",
    "outputId": "4a0550a0-ad23-4b6a-c683-ac9b810c0b2b"
   },
   "outputs": [],
   "source": [
    "image_labels[predicted_label_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple transfer learning\n",
    "\n",
    "But what iweou want to create a custom classifier usin your own dataset that has classes that a ron't included in the original ImageNet dataset (that the pre-trained model was trained ons dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that:\n",
    "\n",
    "1. Select a pre-trained model from TensorFlow Hub; and \n",
    "2. Retrain the top (last) layer to recognize the classes from your custom dataset.\n",
    "\n",
    "### Dataset\n",
    "Use the TensorFlow flowers dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKSyB8rkdrlo"
   },
   "source": [
    "<h3 style='color:purple'>Load flowers dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHYAkhumdrlo",
    "outputId": "2dd47a00-2453-4c7e-9e67-0c800180462e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "\n",
    "# cache_dir indicates where to download data. '.' which means current directory\n",
    "\n",
    "# untar true will unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NFxl-PSrdrlo",
    "outputId": "ceac9f4c-206f-4e89-c1e7-42ff2e35003e"
   },
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAyMWLm1drlp",
    "outputId": "9469000c-a64b-4fc4-9809-fee0067059f6"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3IPMCdGdrlp",
    "outputId": "65078fb4-3f30-4ba1-8a5c-988ef364615b"
   },
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KspXoEO1drlq",
    "outputId": "04ce8fcb-0ebf-41ab-d181-0b6160f94ed5"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "451iO_Yldrlq",
    "outputId": "bd796cd7-38d4-47ec-dabb-dfd5d6a6927e"
   },
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "roses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "cpAPWL77drlq",
    "outputId": "d2004d63-f337-4757-b4ad-5683ac3c2e9b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "STUec3i4drlr",
    "outputId": "d13046e0-4870-449f-9e42-1b3fedde5719"
   },
   "outputs": [],
   "source": [
    "tulips = list(data_dir.glob('tulips/*'))\n",
    "PIL.Image.open(str(tulips[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htbHBL2Ndrlr"
   },
   "source": [
    "<h3 style='color:purple'>Read flowers images from disk into numpy array using opencv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5IRlzCwdrlr"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD2HRHAddrls"
   },
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIr0pw0mdrls",
    "outputId": "2e349403-e35e-428b-bc5a-77f60e3b6c3f"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict['roses'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aFWv3I7rdrls",
    "outputId": "3f5a618c-078a-4be0-f43e-d7a521ecf3fe"
   },
   "outputs": [],
   "source": [
    "str(flowers_images_dict['roses'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGB1ZB9bdrls"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(str(flowers_images_dict['roses'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7bLJc4ydrlt",
    "outputId": "4bd7854f-91a2-4f1e-8ffd-8f756e940e1f"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqQ_jPc7drlt",
    "outputId": "445804d9-c703-4ffb-a751-13f261d91c5f"
   },
   "outputs": [],
   "source": [
    "cv2.resize(img,(224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0lYvlhMdrlt"
   },
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread( str(image) )\n",
    "        if img is not None:\n",
    "            resized_img = cv2.resize(img, (224, 224))\n",
    "            X.append(resized_img)\n",
    "            y.append(flowers_labels_dict[flower_name])\n",
    "        else:\n",
    "            print(f\"Error reading image: {image}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdAwzFM_drlt"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS_Aff6Pdrlu"
   },
   "source": [
    "<h3 style='color:purple'>Train test split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de6let-Wdrlu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txNOtvWcdrlu"
   },
   "source": [
    "<h3 style='color:purple'>Preprocessing: scale images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bHHUMtYdrlu"
   },
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1Aeoh4jdrlv"
   },
   "source": [
    "**Make prediction using pre-trained model on new flowers dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gu7jRwP_drlv",
    "outputId": "fc1e5319-f1f0-437d-f014-017517267f86"
   },
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BA5EuANdrlv",
    "outputId": "ec88b7e0-5659-4371-bcb9-828c146e558c"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE+(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trOqRUH8drlv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0_resized = cv2.resize(X[0], IMAGE_SHAPE)\n",
    "x1_resized = cv2.resize(X[1], IMAGE_SHAPE)\n",
    "x2_resized = cv2.resize(X[2], IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Q-POKk5idrlw",
    "outputId": "5800d1ab-289c-47f1-cdef-db4ed9c412c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "n1PF7GtEdrlw",
    "outputId": "e52d5a1b-cd6d-4e25-8c3e-64666140f023"
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "uRwAPR0tdrlw",
    "outputId": "6f8493fb-fb5f-4ef7-ce7f-d3a9daa43a97"
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfcvLiCUdrlw",
    "outputId": "509eeee6-b394-4e98-ce20-de3be0601bc0"
   },
   "outputs": [],
   "source": [
    "predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5W8OCT10drlx",
    "outputId": "f61ac93c-b2a5-4021-8ecb-dd35b15571ff"
   },
   "outputs": [],
   "source": [
    "image_labels[795]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05s2oYrtdrlx"
   },
   "source": [
    "<h3 style='color:purple'>Added New Layers, Neurons to try and improve accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pv603Rwpdrlx"
   },
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwP0IX2Udrlx",
    "outputId": "82c8a54f-d315-4f31-a0c4-6c819462c9ee"
   },
   "outputs": [],
   "source": [
    "import tf_keras\n",
    "\n",
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
    "\n",
    "num_of_flowers = 5\n",
    "\n",
    "model = tf_keras.Sequential([\n",
    "  pretrained_model_without_top_layer,\n",
    "    tf_keras.layers.BatchNormalization(),\n",
    "    tf_keras.layers.Dropout(0.1),\n",
    "    tf_keras.layers.Dense(64),\n",
    "    tf_keras.layers.Dense(32),\n",
    "  tf_keras.layers.Dense(num_of_flowers)\n",
    "])\n",
    "\n",
    "# Get the pre-trained model's parameters\n",
    "pretrained_model_params = pretrained_model_without_top_layer.trainable_weights\n",
    "\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inb0tViCdrly",
    "outputId": "c2c67e22-3caa-46b9-c20a-461353431648"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10, validation_split = 0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooUwpdDZdrly",
    "outputId": "aad0e6c4-cec7-44c4-e456-44d044926d26"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize to [0, 1] range\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'sun.jpg'\n",
    "\n",
    "test_image = preprocess_image(test_image_path)\n",
    "predictions = model.predict(test_image)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Example class names (should match your dataset structure)\n",
    "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "print(f\"Predicted flower: {class_names[predicted_class[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_transfer_learning.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5640667,
     "sourceId": 9313547,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
